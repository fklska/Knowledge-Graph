# Knowledge-Graph
Описание индустриального проекта по построению графа знаний

1. [Предобработка источников](#Конвертация-документов-в-Markdown)
2. [Пайплайн извлечения сущностей](#LCEL:-Langchain-Expression-language)
3. Организация базы данных
4. LLM Inference

## Введение 
### Существующие подходы
MIT

From local to Global: GraphRAG

Prompt me one more time

## Конвертация документов в Markdown

В качестве входного текста было принято решение использовать `markdown` разметку. Обосновывается это тем, что LLM обучаются на огромных объёмах Markdown-подобных текстов (GitHub, документация, Wiki),
поэтому элементы `Markdown` разметки интерпретируются моделью как сигналы структуры, а не просто символы. Также использование размеченного текста помогает лучше его делить на смысловые части, отделя новые главы, параграфы и темы исходного источника.

В качестве основного метода конвертации документов в `markdown` были выбраны OCR модели. Они показывали хорошие результаты, по сравнению с алгоритмическими методами. Небольшой обзор по текущим OCR решениям можно посмотреть кликнув по картинке. Для нас было важно качественная конвертация таблиц, формул, списков, заголовков, в общем всех структурных элементов. Лучше всего зарекомендовали себя MinerU и Marker
<div>
  <a href="https://miro.com/app/board/uXjVJh4vnAs=/?moveToWidget=3458764655967474926&cot=14">
    <img width="1291" height="1209" alt="изображение" src="https://github.com/user-attachments/assets/d077f250-0df6-43cf-8262-18c84ace756f" />
  </a>
</div>


## LCEL: LangChain Expression Language
Для извлечение сущностей была использована llm - *gpt-oss20b*. Библиотека `Langchain` предоставлет удобный функционал для работы с LLM 

## Neo4j - 
